DELIMITER = ', ' # Data delimiter in the CSV files
NCOLS_PER_CHANNEL = 5 # Number of data columns per phasemeter channel

import sys
import csv
from io import TextIOWrapper
import scipy.io
import zipfile
import tarfile
import gzip
from py7zr import SevenZipFile
import numpy as np
import pandas as pd
import logging
logger = logging.getLogger(__name__)

def read_lines(filename, num_lines):
    """
    Read from file, return a number of lines as list.

    Args:
        filename (string): location of the file
        num_lines (int): number of lines to read from the file

    Returns:
        lines (list): list of strings with `num_lines` lines from file
    """
    lines = []
    try:
        with open(filename, 'r') as file:
            for _ in range(num_lines):
                line = file.readline()
                if not line:
                    break
                lines.append(line.strip())
        return lines
    except Exception as e:
        logger.error(f"Error: {e}")
        sys.exit(1)

def is_mat_file(file_path):
    """Check if a file is a MATLAB .mat file by attempting to read its contents."""
    try:
        scipy.io.whosmat(file_path)  # Try reading variable names in the file
        return True
    except:
        return False

def moku_mat_to_csv(mat_file, out_file=None, delimiter=DELIMITER):
    """
    Convert a MATLAB `.mat` file generated by a Moku:Pro phasemeter into a CSV file.

    Args:
        mat_file (str): Path to the input `.mat` file containing the Moku data.
        out_file (str, optional): Path to the output CSV file. If not provided, 
        the function will save the CSV file with the same name as `mat_file` 
        but with a `.csv` extension.

    Returns:
        None
        The function writes the extracted data to a CSV file and does not return a value.

    Notes:
    ------
    - The function expects a specific structure within the MATLAB file: 
      `mat_data['moku'][0][0][0][0]` for the header and `mat_data['moku'][0][0][1]` 
      for the numerical data.
    - The extracted header is assumed to be a string and is stripped of its last newline.
    - The data is saved with six decimal places of precision.

    """
    mat_data = scipy.io.loadmat(mat_file)

    header = str(mat_data['moku'][0][0][0][0][:-2])

    data_array = mat_data['moku'][0][0][1]

    if out_file is None:
        out_file = mat_file + '.csv'

    np.savetxt(out_file, data_array, delimiter=delimiter, header=header, comments="", fmt="%.14f")

    return out_file

def parse_csv_file(filename, delimiter=None):
    """
    Parse a CSV file. It is potentially packaged in ZIP, TAR, GZ, or 7z format.

    Args:
        filename (str): Location of the file

    Returns:
        num_cols (int): Number of columns in the data
        num_rows (int): Total number of rows (including headers)
        num_header_rows (int): Number of detected header lines
        header (list): List of header lines
    """
    def process_stream(file_obj):
        header_symbols = ['#', '%', '!', '@', ';', '&', '*', '/']
        header = []
        num_header_rows = 0
        num_rows = 0
        data_lines_sample = []
        num_cols = None

        # Wrap binary streams in text wrapper
        if isinstance(file_obj.read(0), bytes):
            file_obj = TextIOWrapper(file_obj, encoding='utf-8')
        file_obj.seek(0)

        for line in file_obj:
            num_rows += 1
            if any(line.startswith(symbol) for symbol in header_symbols):
                header.append(line)
                num_header_rows += 1
            else:
                # Capture a few non-header lines to detect delimiter
                if len(data_lines_sample) < 5 and line.strip():
                    data_lines_sample.append(line)
                # Try to determine number of columns from the first non-empty, non-header line
                if num_cols is None and line.strip():
                    try:
                        sniffed = csv.Sniffer().sniff(''.join(data_lines_sample))
                        detected_delimiter = sniffed.delimiter
                    except csv.Error:
                        detected_delimiter = delimiter if delimiter else ','
                    num_cols = len(line.strip().split(detected_delimiter))
        if num_cols is None:
            raise ValueError("No valid data lines found to determine column count.")
        return num_cols, num_rows, num_header_rows, header

    def process_file(path):
        if zipfile.is_zipfile(path):
            with zipfile.ZipFile(path, 'r') as zip_ref:
                first_file_name = zip_ref.namelist()[0]
                with zip_ref.open(first_file_name, 'r') as f:
                    return process_stream(f)
        elif tarfile.is_tarfile(path):
            with tarfile.open(path, 'r') as tar_ref:
                first_member = tar_ref.getmembers()[0]
                with tar_ref.extractfile(first_member) as f:
                    return process_stream(f)
        elif path.endswith('.gz'):
            with gzip.open(path, 'rb') as f:
                return process_stream(f)
        elif path.endswith('.7z'):
            with SevenZipFile(path, 'r') as seven_zip_ref:
                first_file_name = seven_zip_ref.getnames()[0]
                with seven_zip_ref.open(first_file_name) as f:
                    return process_stream(f)
        else:
            with open(path, 'r', encoding='utf-8') as f:
                return process_stream(f)

    logger.debug(f"Reading from file: {filename}")
    num_cols, num_rows, num_header_rows, header = process_file(filename)

    if num_header_rows == 0:
        raise ValueError("No header lines detected. Ensure the file format is correct.")

    logger.debug(f"File contains {num_rows} total rows, {num_header_rows} header rows, and {num_cols} columns")
    return num_cols, num_rows, num_header_rows, header


def parse_moku_phasemeter_header(file_header, row_fs=None, row_t0=None, fs_hint="rate", t0_hint="Acquired"):
    """
    Parse a Moku phasemeter CSV file header.

    Args:
        header (str): The file header
        row_fs (int, optional): Row number containing acquisition rate
        row_t0 (int, optional): Row number containing start time
        fs_hint (str, optional): String hint to locate the acquisition rate line (default: "rate")
        t0_hint (str, optional): String hint to locate the start time line (default: "Acquired")
    
    Returns:
        date (pd.Timestamp): Start time reported in the file
        fs (float): Sampling frequency
        num_header_lines (int): Number of detected header lines
        num_columns (int): Number of columns in the data
    """
    fs = None
    date = None
    num_header_rows = len(file_header)

    # First attempt to use row_fs if provided
    if row_fs is not None and row_fs <= num_header_rows:
        try:
            fs = float(file_header[row_fs-1].split(': ')[1].split(' ')[0])
        except (IndexError, ValueError):
            logger.warning(f"Failed to parse fs from row {row_fs}, falling back to hint search.")

    # If fs is not found, use hint search
    if fs is None:
        for line in file_header[:num_header_rows]:
            if fs_hint in line:
                try:
                    fs = float(line.split(': ')[1].split(' ')[0])
                    break
                except (IndexError, ValueError):
                    logger.warning(f"Failed to parse fs from line containing {fs_hint}.")

    logger.debug(f'Moku phasemeter metadata:')
    logger.debug(f'    fs = {fs}')

    # First attempt to use row_t0 if provided
    if row_t0 is not None and row_t0 <= num_header_rows:
        try:
            date = pd.to_datetime(file_header[row_t0-1].split(f'% {t0_hint} ')[1].strip())
        except (IndexError, ValueError):
            logger.warning(f"Failed to parse t0 from row {row_t0}, falling back to hint search.")

    # If t0 is not found, use hint search
    if date is None:
        for line in file_header[:num_header_rows]:
            if t0_hint in line:
                try:
                    date = pd.to_datetime(line.split(f'% {t0_hint} ')[1].strip())
                    break
                except (IndexError, ValueError):
                    logger.warning(f"Failed to parse t0 from line containing {t0_hint}.")

    logger.debug(f'    t0 = {date}')
    
    return fs, date

def get_columns_with_nans(df):
    """
    Find columns with NaNs in a DataFrame.

    Args: 
        df (DataFrame): the DataFrame

    Returns:
        columns_with_nans (dict): dictionary of columns with NaNs
    """
    columns_with_nans = {}
    for column in df.columns:
        if df[column].isna().any():
            # Get the column number
            column_number = df.columns.get_loc(column)
            columns_with_nans[column] = column_number
    return columns_with_nans

def display_menu(files):
    """
    Display a menu of options for the user.
    
    Args:
        files (list): list of files the user can choose
    """
    print("\nChoose two CSV files for processing (Master device first):")
    for idx, file in enumerate(files):
        print(f"{idx + 1}. {file}")
    print("Q. Quit")

def get_user_choice(files):
    """
    Get the user's choice of files.
    
    Args:
        files (list): list of potential choices

    Returns:
        ('Q', None) if user chooses to quit
        ('F', file_choices) if user chose two files
    """
    while True:
        choice = input("E.g., enter 1 2 if file #1 is Master and file #2 is Slave (Q to quit): ").strip().upper()
        if choice == 'Q':
            return 'Q', None
        
        try:
            choices = [int(ch) for ch in choice.split()]
            if len(choices) == 2 and all(1 <= ch <= len(files) for ch in choices):
                return 'F', [files[ch - 1] for ch in choices]
        except ValueError:
            pass