DELIMITER = ', ' # Data delimiter in the CSV files
NCOLS_PER_CHANNEL = 5 # Number of data columns per phasemeter channel

import sys
import scipy.io
import numpy as np
import pandas as pd
import logging
logger = logging.getLogger(__name__)

def read_lines(filename, num_lines):
    """
    Read from file, return a number of lines as list.

    Args:
        filename (string): location of the file
        num_lines (int): number of lines to read from the file

    Returns:
        lines (list): list of strings with `num_lines` lines from file
    """
    lines = []
    try:
        with open(filename, 'r') as file:
            for _ in range(num_lines):
                line = file.readline()
                if not line:
                    break
                lines.append(line.strip())
        return lines
    except Exception as e:
        logger.error(f"Error: {e}")
        sys.exit(1)

def is_mat_file(file_path):
    """Check if a file is a MATLAB .mat file by attempting to read its contents."""
    try:
        scipy.io.whosmat(file_path)  # Try reading variable names in the file
        return True
    except:
        return False

def moku_mat_to_csv(mat_file, out_file=None, delimiter=DELIMITER):
    """
    Convert a MATLAB `.mat` file generated by a Moku:Pro phasemeter into a CSV file.

    Args:
        mat_file (str): Path to the input `.mat` file containing the Moku data.
        out_file (str, optional): Path to the output CSV file. If not provided, 
        the function will save the CSV file with the same name as `mat_file` 
        but with a `.csv` extension.

    Returns:
        None
        The function writes the extracted data to a CSV file and does not return a value.

    Notes:
    ------
    - The function expects a specific structure within the MATLAB file: 
      `mat_data['moku'][0][0][0][0]` for the header and `mat_data['moku'][0][0][1]` 
      for the numerical data.
    - The extracted header is assumed to be a string and is stripped of its last newline.
    - The data is saved with six decimal places of precision.

    """
    mat_data = scipy.io.loadmat(mat_file)

    header = str(mat_data['moku'][0][0][0][0][:-2])

    data_array = mat_data['moku'][0][0][1]

    if out_file is None:
        out_file = mat_file + '.csv'

    np.savetxt(out_file, data_array, delimiter=delimiter, header=header, comments="", fmt="%.14f")

    return out_file

def parse_header(filename, row_fs=None, delimiter=DELIMITER, row_t0=None, fs_hint="rate", t0_hint="Acquired"):
    """
    Parse the header of the file.

    Args:
        filename (str): Location of the file
        row_fs (int, optional): Row number containing acquisition rate
        row_t0 (int, optional): Row number containing start time
        fs_hint (str, optional): String hint to locate the acquisition rate line (default: "rate")
        t0_hint (str, optional): String hint to locate the start time line (default: "Acquired")
    
    Returns:
        date (pd.Timestamp): Start time reported in the file
        fs (float): Sampling frequency
        num_header_lines (int): Number of detected header lines
        num_columns (int): Number of columns in the data
    """
    logger.debug(f"Reading metadata from file: {filename}")

    # Read the first 100 lines to detect header
    file_header = read_lines(filename, 100)

    # Detect the number of header lines
    special_chars = {'$', '%', '#', '!', '*'}
    num_header_lines = 0
    for line in file_header:
        if any(char in line for char in special_chars):
            num_header_lines += 1
        else:
            break  # Stop counting when we reach a non-header line

    logger.debug(f"Detected {num_header_lines} header lines")

    if num_header_lines == 0:
        raise ValueError("No header lines detected. Ensure the file format is correct.")

    last_header_line = file_header[num_header_lines - 1]  # Last detected header line
    num_columns = last_header_line.count(delimiter) + 1  # Number of columns based on commas

    logger.debug(f"Detected {num_columns} columns in the data")

    fs = None
    date = None

    # First attempt to use row_fs if provided
    if row_fs is not None and row_fs <= num_header_lines:
        try:
            fs = float(file_header[row_fs-1].split(': ')[1].split(' ')[0])
        except (IndexError, ValueError):
            logger.warning(f"Failed to parse fs from row {row_fs}, falling back to hint search.")

    # If fs is not found, use hint search
    if fs is None:
        for line in file_header[:num_header_lines]:
            if fs_hint in line:
                try:
                    fs = float(line.split(': ')[1].split(' ')[0])
                    break
                except (IndexError, ValueError):
                    logger.warning(f"Failed to parse fs from line containing {fs_hint}.")

    logger.debug(f'    fs = {fs}')

    # First attempt to use row_t0 if provided
    if row_t0 is not None and row_t0 <= num_header_lines:
        try:
            date = pd.to_datetime(file_header[row_t0-1].split(f'% {t0_hint} ')[1].strip())
        except (IndexError, ValueError):
            logger.warning(f"Failed to parse t0 from row {row_t0}, falling back to hint search.")

    # If t0 is not found, use hint search
    if date is None:
        for line in file_header[:num_header_lines]:
            if t0_hint in line:
                try:
                    date = pd.to_datetime(line.split(f'% {t0_hint} ')[1].strip())
                    break
                except (IndexError, ValueError):
                    logger.warning(f"Failed to parse t0 from line containing {t0_hint}.")

    logger.debug(f'    t0 = {date}')

    return date, fs, num_header_lines, num_columns

def get_columns_with_nans(df):
    """
    Find columns with NaNs in a DataFrame.

    Args: 
        df (DataFrame): the DataFrame

    Returns:
        columns_with_nans (dict): dictionary of columns with NaNs
    """
    columns_with_nans = {}
    for column in df.columns:
        if df[column].isna().any():
            # Get the column number
            column_number = df.columns.get_loc(column)
            columns_with_nans[column] = column_number
    return columns_with_nans

def display_menu(files):
    """
    Display a menu of options for the user.
    
    Args:
        files (list): list of files the user can choose
    """
    print("\nChoose two CSV files for processing (Master device first):")
    for idx, file in enumerate(files):
        print(f"{idx + 1}. {file}")
    print("Q. Quit")

def get_user_choice(files):
    """
    Get the user's choice of files.
    
    Args:
        files (list): list of potential choices

    Returns:
        ('Q', None) if user chooses to quit
        ('F', file_choices) if user chose two files
    """
    while True:
        choice = input("E.g., enter 1 2 if file #1 is Master and file #2 is Slave (Q to quit): ").strip().upper()
        if choice == 'Q':
            return 'Q', None
        
        try:
            choices = [int(ch) for ch in choice.split()]
            if len(choices) == 2 and all(1 <= ch <= len(files) for ch in choices):
                return 'F', [files[ch - 1] for ch in choices]
        except ValueError:
            pass